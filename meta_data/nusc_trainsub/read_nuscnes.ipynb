{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from nuscenes.nuscenes import NuScenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 22.322 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 5.2 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "nuscenes_dir = \"/data/nuscene\"\n",
    "nuscenes_version = 'v1.0-trainval'\n",
    "nusc = NuScenes(version=nuscenes_version, dataroot=nuscenes_dir, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nusc.scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2631083"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nusc.sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': 'bddd80ae33ec4e32b27fdb3c1160a30e',\n",
       " 'sample_token': 'e93e98b63d3b40209056d129dc53ceee',\n",
       " 'ego_pose_token': 'bddd80ae33ec4e32b27fdb3c1160a30e',\n",
       " 'calibrated_sensor_token': '7781065816974801afc4dcdaf6acf92c',\n",
       " 'timestamp': 1531883530440378,\n",
       " 'fileformat': 'pcd',\n",
       " 'is_key_frame': True,\n",
       " 'height': 0,\n",
       " 'width': 0,\n",
       " 'filename': 'samples/RADAR_FRONT/n015-2018-07-18-11-07-57+0800__RADAR_FRONT__1531883530440378.pcd',\n",
       " 'prev': '',\n",
       " 'next': '90df03ad4710427aabb5f88fe049df2e',\n",
       " 'sensor_modality': 'radar',\n",
       " 'channel': 'RADAR_FRONT'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.sample_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': '3388933b59444c5db71fade0bbfef470',\n",
       " 'sample_token': 'e93e98b63d3b40209056d129dc53ceee',\n",
       " 'ego_pose_token': '3388933b59444c5db71fade0bbfef470',\n",
       " 'calibrated_sensor_token': '7a0cd258d096410eb68251b4b87febf5',\n",
       " 'timestamp': 1531883530449377,\n",
       " 'fileformat': 'pcd',\n",
       " 'is_key_frame': True,\n",
       " 'height': 0,\n",
       " 'width': 0,\n",
       " 'filename': 'samples/LIDAR_TOP/n015-2018-07-18-11-07-57+0800__LIDAR_TOP__1531883530449377.pcd.bin',\n",
       " 'prev': '',\n",
       " 'next': 'bc2cd87d110747cd9849e2b8578b7877',\n",
       " 'sensor_modality': 'lidar',\n",
       " 'channel': 'LIDAR_TOP'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.get('sample_data', '3388933b59444c5db71fade0bbfef470')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'token': '020d7b4f858147558106c504f7f31bef',\n",
       "  'sample_token': 'e93e98b63d3b40209056d129dc53ceee',\n",
       "  'ego_pose_token': '020d7b4f858147558106c504f7f31bef',\n",
       "  'calibrated_sensor_token': '2e64b091b3b146a390c2606b9081343c',\n",
       "  'timestamp': 1531883530412470,\n",
       "  'fileformat': 'jpg',\n",
       "  'is_key_frame': True,\n",
       "  'height': 900,\n",
       "  'width': 1600,\n",
       "  'filename': 'samples/CAM_FRONT/n015-2018-07-18-11-07-57+0800__CAM_FRONT__1531883530412470.jpg',\n",
       "  'prev': '',\n",
       "  'next': 'caa2bfad0b8a4a8090cb0b803352cbc8',\n",
       "  'sensor_modality': 'camera',\n",
       "  'channel': 'CAM_FRONT'},\n",
       " {'token': '27460c51459c46a6b8a94525793ff813',\n",
       "  'timestamp': 1531883530912460,\n",
       "  'rotation': [-0.6994333436708269,\n",
       "   -0.008033826353508524,\n",
       "   0.00886795507673712,\n",
       "   -0.7145976593638728],\n",
       "  'translation': [1010.2642219746872, 612.7457909015482, 0.0]})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.get('sample_data', '020d7b4f858147558106c504f7f31bef'), nusc.get('ego_pose', '27460c51459c46a6b8a94525793ff813')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': 'e93e98b63d3b40209056d129dc53ceee',\n",
       " 'timestamp': 1531883530449377,\n",
       " 'prev': '',\n",
       " 'next': '14d5adfe50bb4445bc3aa5fe607691a8',\n",
       " 'scene_token': '73030fb67d3c46cfb5e590168088ae39',\n",
       " 'data': {'RADAR_FRONT': 'bddd80ae33ec4e32b27fdb3c1160a30e',\n",
       "  'RADAR_FRONT_LEFT': '1a08aec0958e42ebb37d26612a2cfc57',\n",
       "  'RADAR_FRONT_RIGHT': '282fa8d7a3f34b68b56fb1e22e697668',\n",
       "  'RADAR_BACK_LEFT': '05fc4678025246f3adf8e9b8a0a0b13b',\n",
       "  'RADAR_BACK_RIGHT': '31b8099fb1c44c6381c3c71b335750bb',\n",
       "  'LIDAR_TOP': '3388933b59444c5db71fade0bbfef470',\n",
       "  'CAM_FRONT': '020d7b4f858147558106c504f7f31bef',\n",
       "  'CAM_FRONT_RIGHT': '16d39ff22a8545b0a4ee3236a0fe1c20',\n",
       "  'CAM_BACK_RIGHT': 'ec7096278e484c9ebe6894a2ad5682e9',\n",
       "  'CAM_BACK': 'aab35aeccbda42de82b2ff5c278a0d48',\n",
       "  'CAM_BACK_LEFT': '86e6806d626b4711a6d0f5015b090116',\n",
       "  'CAM_FRONT_LEFT': '24332e9c554a406f880430f17771b608'},\n",
       " 'anns': ['173a50411564442ab195e132472fde71',\n",
       "  '5123ed5e450948ac8dc381772f2ae29a',\n",
       "  'acce0b7220754600b700257a1de1573d',\n",
       "  '8d7cb5e96cae48c39ef4f9f75182013a',\n",
       "  'f64bfd3d4ddf46d7a366624605cb7e91',\n",
       "  'f9dba7f32ed34ee8adc92096af767868',\n",
       "  '086e3f37a44e459987cde7a3ca273b5b',\n",
       "  '3964235c58a745df8589b6a626c29985',\n",
       "  '31a96b9503204a8688da75abcd4b56b2',\n",
       "  'b0284e14d17a444a8d0071bd1f03a0a2']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': '14d5adfe50bb4445bc3aa5fe607691a8',\n",
       " 'timestamp': 1531883530949817,\n",
       " 'prev': 'e93e98b63d3b40209056d129dc53ceee',\n",
       " 'next': 'ae4e0c3aa3f24c91aab599e8b54e9264',\n",
       " 'scene_token': '73030fb67d3c46cfb5e590168088ae39',\n",
       " 'data': {'RADAR_FRONT': 'eaf2d8843bda419a8cd6ea8f028a51f1',\n",
       "  'RADAR_FRONT_LEFT': '4cc0d64e677e41238640a04c71199fcd',\n",
       "  'RADAR_FRONT_RIGHT': '0865ebc0f6654670865308c7190118df',\n",
       "  'RADAR_BACK_LEFT': '3a81d43a8d7444e98037cd2bdb5d9c14',\n",
       "  'RADAR_BACK_RIGHT': 'c58fe23ac7fb4818ba03a45d4a0537f5',\n",
       "  'LIDAR_TOP': '69b793ec8dc44e2fbd33d8cdd16b5a31',\n",
       "  'CAM_FRONT': '27460c51459c46a6b8a94525793ff813',\n",
       "  'CAM_FRONT_RIGHT': '5835df603eed40439681cbc3a01661d7',\n",
       "  'CAM_BACK_RIGHT': 'e5cc25c795804f298c7d23092b9cf9ce',\n",
       "  'CAM_BACK': '96e3b433b4aa4eff93910df3fb8cb0e9',\n",
       "  'CAM_BACK_LEFT': 'f9a1c9a5ebd84553a9ac76e225468f54',\n",
       "  'CAM_FRONT_LEFT': 'b31a7bff91b349f2b4ff8605f9e40285'},\n",
       " 'anns': ['35034272eb1f413187ae7b6affb6ec7a',\n",
       "  '9b677225e4bb432cbc31c87c478ceb74',\n",
       "  '4b1c1acb00c04dfe84e54f64a8381649',\n",
       "  '3b3734f6209a4317bb8734bcc1e6305f',\n",
       "  '9805ac06a19b4159a33ad8b188d2153c',\n",
       "  '21ece7170dfa431bb504e15f68fc40ce',\n",
       "  'dcd27b6faa094aa29e333d91f989dcc1',\n",
       "  'cbb763e674024f688b04e4a61f94ae79',\n",
       "  '69d01f8820954bad83a951ede424bee4',\n",
       "  '405f156885d549ca812e1305eddee42f']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': '27460c51459c46a6b8a94525793ff813',\n",
       " 'sample_token': '14d5adfe50bb4445bc3aa5fe607691a8',\n",
       " 'ego_pose_token': '27460c51459c46a6b8a94525793ff813',\n",
       " 'calibrated_sensor_token': '2e64b091b3b146a390c2606b9081343c',\n",
       " 'timestamp': 1531883530912460,\n",
       " 'fileformat': 'jpg',\n",
       " 'is_key_frame': True,\n",
       " 'height': 900,\n",
       " 'width': 1600,\n",
       " 'filename': 'samples/CAM_FRONT/n015-2018-07-18-11-07-57+0800__CAM_FRONT__1531883530912460.jpg',\n",
       " 'prev': '3f79b6459436470799616c6abf614398',\n",
       " 'next': '0a86299633b249ce8a760d70a5c26865',\n",
       " 'sensor_modality': 'camera',\n",
       " 'channel': 'CAM_FRONT'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.get('sample_data', '27460c51459c46a6b8a94525793ff813')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': '27460c51459c46a6b8a94525793ff813',\n",
       " 'timestamp': 1531883530912460,\n",
       " 'rotation': [-0.6994333436708269,\n",
       "  -0.008033826353508524,\n",
       "  0.00886795507673712,\n",
       "  -0.7145976593638728],\n",
       " 'translation': [1010.2642219746872, 612.7457909015482, 0.0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.get('ego_pose', '27460c51459c46a6b8a94525793ff813')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': '73030fb67d3c46cfb5e590168088ae39',\n",
       " 'log_token': '6b6513e6c8384cec88775cae30b78c0e',\n",
       " 'nbr_samples': 40,\n",
       " 'first_sample_token': 'e93e98b63d3b40209056d129dc53ceee',\n",
       " 'last_sample_token': '40e413c922184255a94f08d3c10037e0',\n",
       " 'name': 'scene-0001',\n",
       " 'description': 'Construction, maneuver between several trucks'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_scene = nusc.scene[0]\n",
    "current_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(602, 165, 83)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usable_scenes = 0\n",
    "rainy = 0\n",
    "night = 0\n",
    "for scene in nusc.scene:\n",
    "    description = scene['description']\n",
    "    if 'rain' in description.lower():\n",
    "        rainy += 1\n",
    "    elif 'night' in description.lower():\n",
    "        night += 1\n",
    "    else:\n",
    "        usable_scenes += 1\n",
    "        \n",
    "usable_scenes, rainy, night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_sample = nusc.get('sample', current_scene['first_sample_token'])\n",
    "camera_data = nusc.get('sample_data', current_sample['data']['CAM_FRONT'])\n",
    "cs_record   = nusc.get('calibrated_sensor', camera_data['calibrated_sensor_token'])\n",
    "ego_record  = nusc.get('ego_pose', camera_data['ego_pose_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': '2e64b091b3b146a390c2606b9081343c',\n",
       " 'sensor_token': '725903f5b62f56118f4094b46a4470d8',\n",
       " 'translation': [1.70079118954, 0.0159456324149, 1.51095763913],\n",
       " 'rotation': [0.4998015430569128,\n",
       "  -0.5030316162024876,\n",
       "  0.4997798114386805,\n",
       "  -0.49737083824542755],\n",
       " 'camera_intrinsic': [[1266.417203046554, 0.0, 816.2670197447984],\n",
       "  [0.0, 1266.417203046554, 491.50706579294757],\n",
       "  [0.0, 0.0, 1.0]]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1010.1102882349232, 610.6567106479714, 0.0]\n",
      "[1010.2642219746872, 612.7457909015482, 0.0]\n",
      "[1010.0616806220463, 614.708717153934, 0.0]\n",
      "[1009.4831449393264, 616.620003155022, 0.0]\n",
      "[1008.4523418645251, 618.5256410102996, 0.0]\n",
      "[1006.7152307896974, 620.602418179178, 0.0]\n",
      "[1004.8563017236978, 622.3386866387929, 0.0]\n",
      "[1003.1868077664784, 623.772338884165, 0.0]\n",
      "[1001.0535195887503, 625.5918859601918, 0.0]\n",
      "[998.8169322057958, 627.5026741637021, 0.0]\n",
      "[996.5608330940794, 629.4446293893993, 0.0]\n",
      "[994.3348022784536, 631.359000340172, 0.0]\n",
      "[992.1817257305318, 633.2097630216495, 0.0]\n",
      "[990.1543898468157, 634.94767460193, 0.0]\n",
      "[988.3657893440474, 636.4787753204015, 0.0]\n",
      "[986.4940809569673, 638.1059100545738, 0.0]\n",
      "[984.7996957419698, 639.6341948365144, 0.0]\n",
      "[983.0837245324498, 641.2712971224029, 0.0]\n",
      "[981.3633438598312, 642.9928276280152, 0.0]\n",
      "[979.9778529258506, 644.4712072725667, 0.0]\n",
      "[978.5970627220781, 646.0184947347914, 0.0]\n",
      "[977.1488168300392, 647.6771902947784, 0.0]\n",
      "[975.6163322042344, 649.4311435998902, 0.0]\n",
      "[973.9819801636215, 651.2259809492517, 0.0]\n",
      "[972.1674381907266, 653.1014106418922, 0.0]\n",
      "[970.1450407500361, 655.0347433789957, 0.0]\n",
      "[967.965532349769, 656.9672156310162, 0.0]\n",
      "[965.6332099482096, 658.9588238600983, 0.0]\n",
      "[963.2582910918119, 660.9699357921855, 0.0]\n",
      "[960.812412567996, 663.0174611213611, 0.0]\n",
      "[958.3319659806574, 665.0775926142076, 0.0]\n",
      "[955.8897657032323, 667.0892834865954, 0.0]\n",
      "[953.4313424553446, 669.0912807443231, 0.0]\n",
      "[950.8955969698706, 671.1173401822969, 0.0]\n",
      "[948.3247348001846, 673.1221682742658, 0.0]\n",
      "[946.2875273946377, 674.6516472768988, 0.0]\n",
      "[943.7392152301582, 676.4565425883169, 0.0]\n",
      "[941.180778367045, 678.2066398940685, 0.0]\n",
      "[938.6433482177079, 679.9627971573926, 0.0]\n",
      "[936.0765889325108, 681.7953311896638, 0.0]\n"
     ]
    }
   ],
   "source": [
    "sample_token = current_scene['first_sample_token']\n",
    "for i in range(current_scene['nbr_samples']):\n",
    "    current_sample = nusc.get('sample', sample_token)\n",
    "    camera_data = nusc.get('sample_data', current_sample['data']['CAM_FRONT'])\n",
    "    cs_record   = nusc.get('calibrated_sensor', camera_data['calibrated_sensor_token'])\n",
    "    ego_record  = nusc.get('ego_pose', camera_data['ego_pose_token'])\n",
    "    print(ego_record['translation'])\n",
    "    sample_token = current_sample['next']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Meta File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': '73030fb67d3c46cfb5e590168088ae39',\n",
       " 'log_token': '6b6513e6c8384cec88775cae30b78c0e',\n",
       " 'nbr_samples': 40,\n",
       " 'first_sample_token': 'e93e98b63d3b40209056d129dc53ceee',\n",
       " 'last_sample_token': '40e413c922184255a94f08d3c10037e0',\n",
       " 'name': 'scene-0001',\n",
       " 'description': 'Construction, maneuver between several trucks'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.scene[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "using_scenes = []\n",
    "from nuscenes.utils.splits import create_splits_scenes\n",
    "scene_splits = create_splits_scenes()\n",
    "train_split=[]\n",
    "val_split=[]\n",
    "for i, scene in enumerate(nusc.scene):\n",
    "    description = scene['description'].lower()\n",
    "    if 'rain' in description or 'night' in description:\n",
    "        continue\n",
    "    if scene['name'] in scene_splits['train']:\n",
    "        train_split.append(i)\n",
    "    if scene['name'] in scene_splits['val']:\n",
    "        val_split.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'nusc_train.txt'\n",
    "\n",
    "train_lines = []\n",
    "\n",
    "for scene_index in train_split:\n",
    "    current_scene = nusc.scene[scene_index]\n",
    "    prior_token  = \"\"\n",
    "    sample_token = current_scene['first_sample_token']\n",
    "    for i in range(current_scene['nbr_samples']):\n",
    "        current_sample = nusc.get('sample', sample_token)\n",
    "\n",
    "        if current_sample['next'] == '': # if it is the final one\n",
    "            break\n",
    "\n",
    "        if prior_token == '': # \n",
    "            prior_token = sample_token\n",
    "            sample_token = current_sample['next']\n",
    "            continue\n",
    "\n",
    "        # Normal ones\n",
    "        next_token = current_sample['next']\n",
    "        train_lines.append(f\"{sample_token},{prior_token},{next_token}\\n\")\n",
    "        prior_token = sample_token\n",
    "        sample_token = next_token\n",
    "        \n",
    "with open(train_file, 'w') as f:\n",
    "    f.writelines(train_lines)\n",
    "\n",
    "val_lines   = []\n",
    "val_file   = 'nusc_val.txt'\n",
    "\n",
    "for scene_index in val_split:\n",
    "    current_scene = nusc.scene[scene_index]\n",
    "    prior_token  = \"\"\n",
    "    sample_token = current_scene['first_sample_token']\n",
    "    for i in range(current_scene['nbr_samples']):\n",
    "        current_sample = nusc.get('sample', sample_token)\n",
    "\n",
    "        if current_sample['next'] == '': # if it is the final one\n",
    "            break\n",
    "\n",
    "        if prior_token == '': # \n",
    "            prior_token = sample_token\n",
    "            sample_token = current_sample['next']\n",
    "            continue\n",
    "\n",
    "        # Normal ones\n",
    "        next_token = current_sample['next']\n",
    "        val_lines.append(f\"{sample_token},{prior_token},{next_token}\\n\")\n",
    "        prior_token = sample_token\n",
    "        sample_token = next_token\n",
    "        \n",
    "with open(val_file, 'w') as f:\n",
    "    f.writelines(val_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from PIL import Image\n",
    "from scipy.spatial.transform import Rotation\n",
    "def get_transformation_matrix(translation, rotation):\n",
    "    \"\"\" Compute transformation matrix T [4x4] from translation [x, y, z] and quaternion rotation [w, x, y, z]\n",
    "    \"\"\"\n",
    "    rotation = Rotation.from_quat([rotation[1], rotation[2], rotation[3], rotation[0]]) #[x, y, z, w]\n",
    "    rotation_matrix = rotation.as_matrix() #[3, 3]\n",
    "    T = np.eye(4)\n",
    "    T[0:3, 0:3] = rotation_matrix\n",
    "    T[0:3, 3] = translation\n",
    "    return T\n",
    "\n",
    "def cam_relative_pose(T_imu2world_0:np.ndarray, T_imu2world_1:np.ndarray, T_imu2cam:np.ndarray):\n",
    "    return T_imu2cam @ np.linalg.inv(T_imu2world_1) @ T_imu2world_0 @ np.linalg.inv(T_imu2cam)\n",
    "\n",
    "def read_image(path:str)->np.ndarray:\n",
    "    '''\n",
    "    read image\n",
    "    inputs:\n",
    "        path(str): image path\n",
    "    returns:\n",
    "        img(np.array): [w,h,c] [r, g, b]\n",
    "    '''\n",
    "    #return np.array(Image.open(path, 'r'))\n",
    "    return Image.open(path, 'r')\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, file):\n",
    "        with open(file, 'r') as f:\n",
    "            self.token_list = [line.strip().split(',') for line in f.readlines()]\n",
    "        \n",
    "        self.nusc_get_sample = partial(nusc.get, 'sample')\n",
    "        self.nusc_get_sample_data = partial(nusc.get, 'sample_data')\n",
    "        self.nusc_get_sensor     = partial(nusc.get, 'calibrated_sensor')\n",
    "        self.nusc_get_ego_pose   = partial(nusc.get, 'ego_pose')\n",
    "        \n",
    "        self.frame_ids = [0]\n",
    "    \n",
    "        self.cameras = ['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_RIGHT', 'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_FRONT_LEFT']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.token_list) * len(self.cameras)\n",
    "    \n",
    "    def get_intrinsic(self, cs_record):\n",
    "        return np.array(cs_record['camera_intrinsic']) #[3, 3]\n",
    "    \n",
    "    def get_extrinsic(self, cs_record):\n",
    "        return get_transformation_matrix(cs_record['translation'], cs_record['rotation'])\n",
    "    \n",
    "    def get_ego_pose(self, ego_record):\n",
    "        return get_transformation_matrix(ego_record['translation'], ego_record['rotation'])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        token_index       = index // len(self.cameras)\n",
    "        camera_type_index = index %  len(self.cameras)\n",
    "        camera_type       = self.cameras[camera_type_index]\n",
    "        \n",
    "        sample_tokens = self.token_list[token_index]\n",
    "        samples        = list(map(self.nusc_get_sample, sample_tokens))\n",
    "        camera_datas   = list(map(self.nusc_get_sample_data, [sample['data'][camera_type] for sample in samples]))\n",
    "        cs_records     = list(map(self.nusc_get_sensor, [camera_data['calibrated_sensor_token'] for camera_data in camera_datas]))\n",
    "        ego_records    = list(map(self.nusc_get_ego_pose, [camera_data['ego_pose_token'] for camera_data in camera_datas]))\n",
    "        \n",
    "        image_arrays   = list(map(\n",
    "            read_image, [os.path.join(nuscenes_dir, camera_data['filename']) for camera_data in camera_datas]\n",
    "        ))\n",
    "        #image_arrays   = list(map(\n",
    "        #    np.array, images\n",
    "        #))\n",
    "        P2 = self.get_intrinsic(cs_records[0])\n",
    "        extrinsics = list(map(self.get_extrinsic, cs_records)) #[T] 4 x 4 x 3\n",
    "        poses      = list(map(self.get_ego_pose, ego_records)) #[T] 4 x 4 x 3\n",
    "        \n",
    "        data = dict()\n",
    "        for i, frame_id in enumerate(self.frame_ids):\n",
    "            data[('image', frame_id)] = image_arrays[i]\n",
    "        \n",
    "        data['P2'] = np.zeros((3, 4))\n",
    "        data['P2'][0:3, 0:3] = P2\n",
    "        \n",
    "        for i, idx in enumerate(self.frame_ids[1:]):\n",
    "            data[('relative_pose', idx)] = cam_relative_pose(\n",
    "                poses[0], poses[i+1], np.linalg.inv(extrinsics[0])\n",
    "            )\n",
    "        return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset('nusc_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 1600, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.resize()\n",
    "np.array(data[('image', 0)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('image', -1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2d6ac38fb8fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('image', -1)"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(data[('image', -1)])\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(data[('image', 0)])\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(data[('image', 1)])\n",
    "\n",
    "print(data[('relative_pose', -1)])\n",
    "print(data[('relative_pose', 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "unfound_scene = set()\n",
    "usable_scene = set()\n",
    "for index in range(len(dataset)):\n",
    "    sample = nusc.get('sample', train_lines[index // 6].strip().split(',')[0])\n",
    "    scene = nusc.get('scene', sample['scene_token'])\n",
    "    try: \n",
    "        data = dataset[index]\n",
    "        usable_scene.add(scene['name'])\n",
    "    except FileNotFoundError:\n",
    "        split_index = index\n",
    "        unfound_scene.add(scene['name'])\n",
    "    finally:\n",
    "        pass\n",
    "#unfound_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 765)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unfound_scene), len(usable_scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "76 + 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_data = nusc.get('sample_data', current_sample['data']['CAM_FRONT'])\n",
    "cs_record   = nusc.get('calibrated_sensor', camera_data['calibrated_sensor_token'])\n",
    "ego_record  = nusc.get('ego_pose', camera_data['ego_pose_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_record['camera_intrinsic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4967dbb7fa484682ad75504a986b94b1'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lines[5256].strip().split(',')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 5256\n",
    "split_index = index // 6 + 2\n",
    "camera      = index % 6\n",
    "\n",
    "sample = nusc.get('sample', train_lines[split_index].strip().split(',')[0])\n",
    "camera_data = nusc.get('sample_data', sample['data']['CAM_FRONT_RIGHT'])\n",
    "scene = nusc.get('scene', sample['scene_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/nuscene/samples/CAM_FRONT_RIGHT/n015-2018-11-21-19-21-35+0800__CAM_FRONT_RIGHT__1542799563870339.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-c448c8e60e73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m Image.open(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnuscenes_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2903\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2904\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2905\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/nuscene/samples/CAM_FRONT_RIGHT/n015-2018-11-21-19-21-35+0800__CAM_FRONT_RIGHT__1542799563870339.jpg'"
     ]
    }
   ],
   "source": [
    "Image.open(\n",
    "    os.path.join(nuscenes_dir, camera_data['filename'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': 'afbc2583cc324938b2e8931d42c83e6b',\n",
       " 'log_token': 'e55205b1f2894b49957905d7ddfdb96d',\n",
       " 'nbr_samples': 40,\n",
       " 'first_sample_token': '21bb21c84c3e43908cd554db2686278f',\n",
       " 'last_sample_token': '887e6f18b1b341d9b55bc4289c2e0388',\n",
       " 'name': 'scene-1066',\n",
       " 'description': 'Night, bump, scooter, difficult lighting'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
